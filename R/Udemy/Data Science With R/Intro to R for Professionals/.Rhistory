? geom_smooth
p <- ggplot(data = mtcars, aes(x = mpg, y = hp)) +
geom_point()+
geom_smooth(method = "lm") +
ggtitle("HP vs MPG mtcar data")
p
p2 <- ggplotly(p)
saveWidget(p2, "mpg_vs_hp.html")
areaOfCircle <- function(radius) {
area <- pi * radius^2
return(area)
}
area
areaOfCircle(10)
pi
pi*10
pi
#Give radius a default value of 1
areaOfCircle <- function(radius = 1) {
area <- pi * radius^2
proof_of_concept <- 10
return(area)
}
proof_of_concept
e, but we could give radius a default value (below).
#Give radius a default value of 1
areaOfCircle <- function(radius = 1) {
area <- pi * radius^2
proof_of_concept <- 10
return(area, 10)
}
areaOfCircle()
circleParams <- function(radius = 1){
area <- pi * radius^2
circumference <- 2 * pi * radius
result <- list(area = area, circumference = circumference)
return(result)
}
circle_info <- circleParams(radius = 10)
circle_info
circle_info$area
a <- mtcars
a
str(mtcars)
a <- mtcars %>%
mutate(cyl = as.integer(cyl))
library(dplyr)
a <- mtcars %>%
mutate(cyl = as.integer(cyl))
str(a)
b <- a %>%
group_by(cyl) %>%
summarize_all(mean)
b
library(ggplot2)
p <- ggplot(a) +
geom_point(aes(x=hp, y=disp))+
facet_wrap(~cyl, ncol = 2)
p
#Data Tidying ------------------------------------------------------------ The
#above example of code represents the core lanuage and programing patterns of R.
#The rest of the example code deals with using tidyverse to explore and analyze
#some data.  You'll see that much of the above code is not used in the
#tidyverse.  Tidyverse is a very comprehensive set of tools, but they are not
#perfect, and you will need to know the R fundamentals.  Without the
#fundamentals, R remains a collection of tools rather than a language for
#exploring your ideas.
#Tidying data.  The concept of tidy data was put forward by data scientists from
#R Studio.  Tidy data refers to organizing our information in such a way that
#makes it easy to analyze and visualize.  Furthermore, by keeping our data in a
#consistent structure, the code we develop for anlaysis can be more easily
#re-used.
#There are three rules to tidy data:
#1. Each variable must have its own column.
#2. Each observation must have its own row.
#3. Each value must have its own cell.
#Looking at the above characteristics, the first reaction most people have is
#that nearly all data sets are tidy.  In fact, it is the opposite case.  See the
#slide handouts for data sets that are 'too wide' or 'too narrow'.
#load tidyverse
library(tidyverse)
#load our data sets
commute_data_raw <- read.csv("data/commute_data.csv")
hr_performance_data_raw <- read.csv("data/hr_employees_performance_data.csv")
personal_data_raw <- read.csv("data/personal_data.csv", stringsAsFactors = FALSE)
rnd_performance_data_raw <- read.csv("data/research_and_development_employees_performance_data.csv")
sales_performance_data_raw <- read.csv("data/sales_employees_performance_data.csv")
#examine our data
str(commute_data_raw)
str(personal_data_raw)
str(hr_performance_data_raw)
str(rnd_performance_data_raw)
str(sales_performance_data_raw)
#We see that there is a column called X in each of our data sets.  This appears
#to be a data glitch (this sometimes happens when getting data from Excel when
#the user has some content in a column and then clears the content rather than
#deleteing the column)
#Remove the X columns with the select() function
#Lets also rename our modified data sets so that we keep our raw data untouched.
commutes_data <- commute_data_raw %>%
select(-X)
hr_performance_data <- hr_performance_data_raw %>%
select(-X)
rnd_performance_data <- rnd_performance_data_raw %>%
select(-X)
sales_performance_data <- sales_performance_data_raw %>%
select(-X)
#combine performance data
#we want to be able to identify an employee's department, so we'll make a new variable for this
hr_performance_data <- hr_performance_data %>%
mutate(Department = "HR")
rnd_performance_data <- rnd_performance_data %>%
mutate(Department = "Research and Development")
sales_performance_data <- sales_performance_data %>%
mutate(Department = "Sales")
#Now we can combine our performance data, they all have the same variables
performance_data <- rbind(hr_performance_data,
rnd_performance_data,
sales_performance_data)
#Department should probably be a category not just text - change it to factor
performance_data <- performance_data %>%
mutate(Department = as.factor(Department))
#We can see that the commute data and the performance data share the same
#employee id variable - we can use this to join the data sets together.  The
#dplyr package offers many join functions to help with this.
#left_join performance and commute will give us all the rows from performance,
#right_join will give all the rows from commute, inner_join will give us only
#the rows where there is a match in employee id.  Ideally, all three will return
#the same result.
employee_data <- left_join(performance_data, commutes_data, by = "EmployeeNumber")
#Now lets work on the personal data set... Unlike the other data, personal is
#not tidy, each varible does not have its own column.  Use tidyr to spread out
#the data.  Once the data has been spread we see that all the values are chr -
#we need to coerce the data to the proper types.
personal_data <- personal_data_raw %>%
spread(key = Variable, value = Value) %>%
mutate(Attrition = as.factor(Attrition),
Education = as.integer(Education),
EducationField = as.factor(EducationField),
Gender = as.factor(Gender),
Age = as.integer(Age),
MaritalStatus = as.factor(MaritalStatus),
RelationshipSatisfaction = as.integer(RelationshipSatisfaction)) %>%
select(-EmployeeCount)
#We can now tie this in with our other data
employee_data <- inner_join(employee_data, personal_data, by = "EmployeeNumber")
#Lets takes a look at our data set and trim where we can
str(employee_data)
#Firstly, we see that we have dailyrate, hourlyrate, monthlyincome, and monthly
#rate.  Secondly, we also have a lot of integer data which are actually categories
#Check if the various rates are telling us the same thing.
library(corrgram)
rates <- employee_data %>%
select(DailyRate, HourlyRate, MonthlyRate, MonthlyIncome)
corrgram(rates, upper.panel = panel.conf,lower.panel =  panel.pts)
#These variables are not correlated at all.  We should keep them for the time
#being. Looking at employee standard hours, we see that the variable doesn't
#change - we can get rid of it too.  Same with over18
employee_data <- employee_data %>%
select(-StandardHours, -Over18)
#We need to convert some data to factors.
employee_data <- employee_data %>%
mutate(EnvironmentSatisfaction = as.factor(EnvironmentSatisfaction),
JobInvolvement = as.factor(JobInvolvement),
JobLevel = as.factor(JobLevel),
JobSatisfaction = as.factor(JobSatisfaction),
PerformanceRating = as.factor(PerformanceRating),
StockOptionLevel = as.factor(StockOptionLevel),
WorkLifeBalance = as.factor(WorkLifeBalance),
Education = as.factor(Education),
RelationshipSatisfaction = as.factor(RelationshipSatisfaction)
)
#There are a lot of variables in our dataset, let's use a decision tree algo to
#help identify some variables that are likely important
library(party)
library(caret)  #needed for the confusion matrix
#First we need to split our data into a training set and a test set:
dataSpliter <- function(employee_data, p = 0.7){
set.seed(10)
num_obs <- dim(employee_data)[1]
draw = sample(1:num_obs, replace = FALSE)
draw_split <- floor(num_obs * p)
train = employee_data[draw[1:draw_split], ]
test = employee_data[draw[(draw_split + 1):num_obs], ]
result <- list(train = train, test = test)
return(result)
}
employee_allsets <- dataSpliter(employee_data, p = 0.7)
employee_trainset <- employee_allsets$train
employee_testset <- employee_allsets$test
train_ctree <- ctree(data = employee_trainset, formula = Attrition ~ BusinessTravel +
DailyRate +
EnvironmentSatisfaction +
JobInvolvement)
#The above tree indicates that the Environment Satisfaction plays the most
#important role in whether an employee stays
#Let's see how our model does to predict the results from our testset
predict_ctree <- predict(train_ctree, employee_testset)
confusionMatrix(predict_ctree, employee_testset$Attrition)
#Hurray! 86% accuracy!, but wait... this is a bit misleading since the vast
#majority of employees will remain.  Looking at the confusion matrix, we
#predicted hardly any of the employees who actually left, only the ones that
#stayed.
#Let's try again with more variables in our model
train_ctree <- ctree(data = employee_trainset, formula = Attrition ~ BusinessTravel +
DailyRate +
EnvironmentSatisfaction +
HourlyRate +
JobInvolvement +
JobLevel +
JobRole +
JobSatisfaction +
MonthlyIncome +
MonthlyRate +
NumCompaniesWorked +
OverTime +
PercentSalaryHike +
PerformanceRating +
StockOptionLevel +
TotalWorkingYears +
TrainingTimesLastYear +
WorkLifeBalance +
YearsAtCompany +
YearsInCurrentRole +
YearsSinceLastPromotion +
YearsWithCurrManager +
Department +
DistanceFromHome +
Education +
EducationField +
Gender +
MaritalStatus +
RelationshipSatisfaction +
Age
)
predict_ctree <- predict(train_ctree, employee_testset)
confusionMatrix(predict_ctree, employee_testset$Attrition)
str(employee_trainset)
plot (train_ctree)
library(randomForest)
rand_forest <- randomForest(Attrition ~ ., data = employee_trainset, importance = TRUE)
predict_forest <- predict(rand_forest, employee_testset)
confusionMatrix(predict_forest, employee_testset$Attrition)
importance(rand_forest)
plot(rand_forest)
install.packages("randomForest")
library(plotly)
#load tidyverse
library(tidyverse)
#load our data sets
commute_data_raw <- read.csv("data/commute_data.csv")
hr_performance_data_raw <- read.csv("data/hr_employees_performance_data.csv")
personal_data_raw <- read.csv("data/personal_data.csv", stringsAsFactors = FALSE)
rnd_performance_data_raw <- read.csv("data/research_and_development_employees_performance_data.csv")
sales_performance_data_raw <- read.csv("data/sales_employees_performance_data.csv")
#examine our data
str(commute_data_raw)
str(personal_data_raw)
str(hr_performance_data_raw)
str(rnd_performance_data_raw)
str(sales_performance_data_raw)
#We see that there is a column called X in each of our data sets.  This appears
#to be a data glitch (this sometimes happens when getting data from Excel when
#the user has some content in a column and then clears the content rather than
#deleteing the column)
#Remove the X columns with the select() function
#Lets also rename our modified data sets so that we keep our raw data untouched.
commutes_data <- commute_data_raw %>%
select(-X)
hr_performance_data <- hr_performance_data_raw %>%
select(-X)
rnd_performance_data <- rnd_performance_data_raw %>%
select(-X)
sales_performance_data <- sales_performance_data_raw %>%
select(-X)
#combine performance data
#we want to be able to identify an employee's department, so we'll make a new variable for this
hr_performance_data <- hr_performance_data %>%
mutate(Department = "HR")
rnd_performance_data <- rnd_performance_data %>%
mutate(Department = "Research and Development")
sales_performance_data <- sales_performance_data %>%
mutate(Department = "Sales")
#Now we can combine our performance data, they all have the same variables
performance_data <- rbind(hr_performance_data,
rnd_performance_data,
sales_performance_data)
#Department should probably be a category not just text - change it to factor
performance_data <- performance_data %>%
mutate(Department = as.factor(Department))
#We can see that the commute data and the performance data share the same
#employee id variable - we can use this to join the data sets together.  The
#dplyr package offers many join functions to help with this.
#left_join performance and commute will give us all the rows from performance,
#right_join will give all the rows from commute, inner_join will give us only
#the rows where there is a match in employee id.  Ideally, all three will return
#the same result.
employee_data <- left_join(performance_data, commutes_data, by = "EmployeeNumber")
#Now lets work on the personal data set... Unlike the other data, personal is
#not tidy, each varible does not have its own column.  Use tidyr to spread out
#the data.  Once the data has been spread we see that all the values are chr -
#we need to coerce the data to the proper types.
personal_data <- personal_data_raw %>%
spread(key = Variable, value = Value) %>%
mutate(Attrition = as.factor(Attrition),
Education = as.integer(Education),
EducationField = as.factor(EducationField),
Gender = as.factor(Gender),
Age = as.integer(Age),
MaritalStatus = as.factor(MaritalStatus),
RelationshipSatisfaction = as.integer(RelationshipSatisfaction)) %>%
select(-EmployeeCount)
#We can now tie this in with our other data
employee_data <- inner_join(employee_data, personal_data, by = "EmployeeNumber")
#Lets takes a look at our data set and trim where we can
str(employee_data)
#Firstly, we see that we have dailyrate, hourlyrate, monthlyincome, and monthly
#rate.  Secondly, we also have a lot of integer data which are actually categories
#Check if the various rates are telling us the same thing.
library(corrgram)
rates <- employee_data %>%
select(DailyRate, HourlyRate, MonthlyRate, MonthlyIncome)
corrgram(rates, upper.panel = panel.conf,lower.panel =  panel.pts)
#These variables are not correlated at all.  We should keep them for the time
#being. Looking at employee standard hours, we see that the variable doesn't
#change - we can get rid of it too.  Same with over18
employee_data <- employee_data %>%
select(-StandardHours, -Over18)
#We need to convert some data to factors.
employee_data <- employee_data %>%
mutate(EnvironmentSatisfaction = as.factor(EnvironmentSatisfaction),
JobInvolvement = as.factor(JobInvolvement),
JobLevel = as.factor(JobLevel),
JobSatisfaction = as.factor(JobSatisfaction),
PerformanceRating = as.factor(PerformanceRating),
StockOptionLevel = as.factor(StockOptionLevel),
WorkLifeBalance = as.factor(WorkLifeBalance),
Education = as.factor(Education),
RelationshipSatisfaction = as.factor(RelationshipSatisfaction)
)
#Now let start looking at our data...
#Lets look at attrition by gender using the group_by function
a <- employee_data %>%
select(Gender, Attrition) %>%
group_by(Gender, Attrition) %>%
summarise(Count = n()) %>%
spread(key = Attrition, value = Count) %>%
mutate(PercentAttrition = Yes/(Yes + No))
a
#Lets look at attrition by gender and by department (note we only have to change 2 lines of code!)
a <- employee_data %>%
select(Gender, Attrition, Department) %>%
group_by(Department, Gender, Attrition) %>%
summarise(Count = n()) %>%
spread(key = Attrition, value = Count) %>%
mutate(PercentAttrition = Yes/(Yes + No))
a
#Let look at attrition by gender and by department for people over 40
over_forty <- dplyr::filter(employee_data, Age >= 40)
a <- over_forty %>%
select(Gender, Attrition, Department) %>%
group_by(Department, Gender, Attrition) %>%
summarise(Count = n()) %>%
spread(key = Attrition, value = Count) %>%
mutate(PercentAttrition = Yes/(Yes + No))
a
#Lets take a look at commutes
a <- employee_data %>%
select(Attrition, DistanceFromHome) %>%
group_by(Attrition) %>%
summarise(AvgDist = mean(DistanceFromHome),
StdevDist = sd(DistanceFromHome))
#We can see that tidyr and dplyr make us quite the data gymnasts! With Excel,
#the 'how about this?' and the 'could-you-actually?' can mean a lot of work.
#With these libraries, it can be a matter of one or two lines of code!
#Lets start visualizing our data with ggplot2 ggplot2 stores our graphics object
#as a ggplot object.  ggplot2 offers a layered approach to building our
#visualzations.  First we specify the data set, then we specify the aesthetic
#relationships (i.e. how we actually want to see our variables.  do we want
#attriion on the x-axis?).  The next layer is a geom layer which describes the
#type of graph we're creating.
library(ggplot2)
p1 <- ggplot(data = employee_data, aes(x=Attrition, y=HourlyRate)) +
geom_boxplot()
p1
#lets also look at department
p1 <- ggplot(data = employee_data, aes(x=Attrition, y=HourlyRate, fill = Department)) +
geom_boxplot()
p1
#lets show the distribution another way.  facetting allows us to break down a
#graph into multpile graphs by a category.
p1 <- ggplot(data = employee_data, aes(x=HourlyRate, fill = Attrition)) +
geom_density(alpha = 0.4) +
facet_wrap(~Department, ncol=1)
p1
p1 <- ggplot(data = employee_data, aes(x=HourlyRate, fill = Attrition)) +
geom_histogram(alpha = 0.4) +
facet_wrap(~Department, ncol=1)
p1
#If you'd like different color schemes, you can set your own pallets, or you can
#use some from the ggthemes package.  Be careful that you have enough different
#colors for the number of variables that you wish to plot!
library(ggthemes)
p1 <- ggplot(data = employee_data, aes(x=HourlyRate, fill = Attrition)) +
geom_histogram(alpha = 0.4) +
facet_wrap(~Department, ncol=1) +
scale_fill_fivethirtyeight()
p1
#create a scatterplot of YearsAtCompany vs age
p1 <- ggplot(data = employee_data, aes(x = Age, y = YearsAtCompany, color = Attrition)) +
geom_point() +
geom_smooth()
p1
p1 <- ggplot(data = employee_data, aes(x = Age, y = YearsAtCompany )) +
geom_point(aes(color = Attrition)) +
geom_smooth()
p1
#lets see how job performance factors in...
#below doesn't work, can't use integers for categories!
p1 <- ggplot(data = employee_data, aes(x = Attrition, fill = PerformanceRating)) +
geom_bar(position = "dodge")
p1
p1 <- ggplot(data = employee_data, aes(x = Attrition, fill = as.factor(PerformanceRating))) +
geom_bar(position = "dodge")
p1
#Another good library for creating graphs is ggvis.
library(ggvis)
employee_data %>%
ggvis(x = ~factor(Education), fill = ~Attrition) %>%
layer_bars()
employee_data %>%
ggvis(x = ~Gender, fill = ~Attrition) %>%
layer_bars()
#There are a lot of variables in our dataset, let's use a decision tree algo to
#help identify some variables that are likely important
library(party)
library(caret)  #needed for the confusion matrix
#First we need to split our data into a training set and a test set:
dataSpliter <- function(employee_data, p = 0.7){
set.seed(10)
num_obs <- dim(employee_data)[1]
draw = sample(1:num_obs, replace = FALSE)
draw_split <- floor(num_obs * p)
train = employee_data[draw[1:draw_split], ]
test = employee_data[draw[(draw_split + 1):num_obs], ]
result <- list(train = train, test = test)
return(result)
}
employee_allsets <- dataSpliter(employee_data, p = 0.7)
employee_trainset <- employee_allsets$train
employee_testset <- employee_allsets$test
train_ctree <- ctree(data = employee_trainset, formula = Attrition ~ BusinessTravel +
DailyRate +
EnvironmentSatisfaction +
JobInvolvement)
#The above tree indicates that the Environment Satisfaction plays the most
#important role in whether an employee stays
#Let's see how our model does to predict the results from our testset
predict_ctree <- predict(train_ctree, employee_testset)
confusionMatrix(predict_ctree, employee_testset$Attrition)
#Hurray! 86% accuracy!, but wait... this is a bit misleading since the vast
#majority of employees will remain.  Looking at the confusion matrix, we
#predicted hardly any of the employees who actually left, only the ones that
#stayed.
#Let's try again with more variables in our model
train_ctree <- ctree(data = employee_trainset, formula = Attrition ~ BusinessTravel +
DailyRate +
EnvironmentSatisfaction +
HourlyRate +
JobInvolvement +
JobLevel +
JobRole +
JobSatisfaction +
MonthlyIncome +
MonthlyRate +
NumCompaniesWorked +
OverTime +
PercentSalaryHike +
PerformanceRating +
StockOptionLevel +
TotalWorkingYears +
TrainingTimesLastYear +
WorkLifeBalance +
YearsAtCompany +
YearsInCurrentRole +
YearsSinceLastPromotion +
YearsWithCurrManager +
Department +
DistanceFromHome +
Education +
EducationField +
Gender +
MaritalStatus +
RelationshipSatisfaction +
Age
)
predict_ctree <- predict(train_ctree, employee_testset)
confusionMatrix(predict_ctree, employee_testset$Attrition)
plot(train_ctree)
library(randomForest)
rand_forest <- randomForest(Attrition ~ ., data = employee_trainset, importance = TRUE)
predict_forest <- predict(rand_forest, employee_testset)
confusionMatrix(predict_forest, employee_testset$Attrition)
train_ctree <- ctree(data = employee_trainset, formula = Attrition ~ .)
predict_ctree <- predict(train_ctree, employee_testset)
confusionMatrix(predict_ctree, employee_testset$Attrition)
str(employee_data)
shiny::runApp('C:/Users/Greg/Desktop/asdf')
? plotOutput
? sliderInput
runApp('Shiny')
? dev.off()
